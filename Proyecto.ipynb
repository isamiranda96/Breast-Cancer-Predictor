{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto\n",
    "\n",
    "\n",
    "En este proyecto vamos a hacer machine learning aplicado al ámbito medico ,específicamente diagnostico medico.\n",
    "Vamos a crear una aplicación que ayuda a diagnosticar si un tumor de seno es cancerígeno (maligno) o no (benigno)   .\n",
    "Para lograr esto vamos a utilizar un set de datos recopilado por diversos médicos , el cual contiene características de tumores de seno y el diagnostico final . Este es un problema de clasificación binaria ya que solo tenemos dos clases(maligno o benigno), se va a implementar regresión logística para obtener la probabilidad de que el tumor sea maligno.\n",
    "\n",
    "<img src=\"images/ai_cancer.png\" width=\"300\">\n",
    "\n",
    "Según lo visto en la clase en este proyecto el estudiante hará  todo el proceso de entrenamiento, evaluación y selección del modelo de machine learning(pasos 1 al 5 del diagrama de flujo de ejemplo) ,luego de seleccionar el mejor va a exportar el modelo (como fue explicado en la clase deployment/despliegue de modelos y va a entregarlo al profesor) ya que  este será utilizado dentro de una aplicación móvil (desarrollada por el profesor, paso 6 del diagrama )\n",
    "\n",
    "\n",
    "<img src=\"images/diagrama.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import datetime\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registro de Experimentos\n",
    "En machine learning y ciencia de datos es importante tener un registro de los resultados de cada experimento realizado, así como la configuración del sistema(tal como learning-rate, numero de iteraciones, cantidad de observaciones y features, etc) que llevo a determinados resultados, esto porque el proceso puede llegar a ser muy iterativo y nos es útil saber en todo momento que caso tuvo los mejores resultados. Por esta razón en este proyecto utilizamos una bitácora o log-book científico en el cual tenemos la configuración de nuestros modelos y los resultados(métricas de evaluación) de cada uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_book = helper.load_log_book()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez la bitacora contenga informacion ,puedes consultarla en cualquier celda usando:\n",
    "\n",
    "helper.print_log_book(log_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para guardar la bitacora (una vez has capturado el resultado de los experimentos que realizaremos) usaremos el siguiente codigo(hay mas detalles mas adelante)\n",
    "\n",
    "helper.guardar_log_book(log_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carnet estudiante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " La aplicación móvil resultante tendrá un modelo por estudiante, por lo cual es importante identificar a que estudiante pertenece cada modelo, por esta razón  en el proceso de exportar el modelo el archivo resultante tendrá en su nombre el carnet del estudiante. \n",
    " \n",
    " En una variable deben ingresar su numero de carnet, para que al exportar el modelo el archivo se llame `carnet+\"model.csv\"`. Por ejemplo 200818835model.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carnet = \"20150263\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Data Set\n",
    "\n",
    "El dataset que usaremos contiene varias características(features) , más adelante encontraras instrucciones de cómo trabajar con estas. En el siguiente enlace puedes acceder a mayor información y detalles del dataset.\n",
    "\n",
    "[Link al set de datos](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer)\n",
    "\n",
    "#### Data Set Information:\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. A few of the images can be found at [Web Link] \n",
    "\n",
    "Separating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree. Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes. \n",
    "\n",
    "The actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es un problema de clasificacion binario por que que existen solo dos posibles valores(predecimos tumores cancerigenos de seno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['malignant', 'benign'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El data set tiene varios features, por lo  que debemos experimentar con diferentes features y analizar los resultados, en esta celda vamos a imprimir los nombres de las features que poseemos.\n",
    "\n",
    "En este [link](https://goo.gl/U2Uwz2) podemos encontrar mas información sobre las features.\n",
    "\n",
    "Nota: Aunque a lo largo del proyecto, usaremos distintas features para entrenar diversos modelos y entender cómo funciona el proceso de ML y el impacto del uso de diversas features, en el resultado final (el modelo que será exportado e integrado a la aplicación móvil) solo usaremos las primeras 5 features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
       "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points', 'worst symmetry', 'worst fractal dimension'],\n",
       "      dtype='<U23')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "muestra de las primeras 5 labels/etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "las features para estos 5 casos de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.79900000e+01,   1.03800000e+01,   1.22800000e+02,\n",
       "          1.00100000e+03,   1.18400000e-01,   2.77600000e-01,\n",
       "          3.00100000e-01,   1.47100000e-01,   2.41900000e-01,\n",
       "          7.87100000e-02,   1.09500000e+00,   9.05300000e-01,\n",
       "          8.58900000e+00,   1.53400000e+02,   6.39900000e-03,\n",
       "          4.90400000e-02,   5.37300000e-02,   1.58700000e-02,\n",
       "          3.00300000e-02,   6.19300000e-03,   2.53800000e+01,\n",
       "          1.73300000e+01,   1.84600000e+02,   2.01900000e+03,\n",
       "          1.62200000e-01,   6.65600000e-01,   7.11900000e-01,\n",
       "          2.65400000e-01,   4.60100000e-01,   1.18900000e-01],\n",
       "       [  2.05700000e+01,   1.77700000e+01,   1.32900000e+02,\n",
       "          1.32600000e+03,   8.47400000e-02,   7.86400000e-02,\n",
       "          8.69000000e-02,   7.01700000e-02,   1.81200000e-01,\n",
       "          5.66700000e-02,   5.43500000e-01,   7.33900000e-01,\n",
       "          3.39800000e+00,   7.40800000e+01,   5.22500000e-03,\n",
       "          1.30800000e-02,   1.86000000e-02,   1.34000000e-02,\n",
       "          1.38900000e-02,   3.53200000e-03,   2.49900000e+01,\n",
       "          2.34100000e+01,   1.58800000e+02,   1.95600000e+03,\n",
       "          1.23800000e-01,   1.86600000e-01,   2.41600000e-01,\n",
       "          1.86000000e-01,   2.75000000e-01,   8.90200000e-02],\n",
       "       [  1.96900000e+01,   2.12500000e+01,   1.30000000e+02,\n",
       "          1.20300000e+03,   1.09600000e-01,   1.59900000e-01,\n",
       "          1.97400000e-01,   1.27900000e-01,   2.06900000e-01,\n",
       "          5.99900000e-02,   7.45600000e-01,   7.86900000e-01,\n",
       "          4.58500000e+00,   9.40300000e+01,   6.15000000e-03,\n",
       "          4.00600000e-02,   3.83200000e-02,   2.05800000e-02,\n",
       "          2.25000000e-02,   4.57100000e-03,   2.35700000e+01,\n",
       "          2.55300000e+01,   1.52500000e+02,   1.70900000e+03,\n",
       "          1.44400000e-01,   4.24500000e-01,   4.50400000e-01,\n",
       "          2.43000000e-01,   3.61300000e-01,   8.75800000e-02],\n",
       "       [  1.14200000e+01,   2.03800000e+01,   7.75800000e+01,\n",
       "          3.86100000e+02,   1.42500000e-01,   2.83900000e-01,\n",
       "          2.41400000e-01,   1.05200000e-01,   2.59700000e-01,\n",
       "          9.74400000e-02,   4.95600000e-01,   1.15600000e+00,\n",
       "          3.44500000e+00,   2.72300000e+01,   9.11000000e-03,\n",
       "          7.45800000e-02,   5.66100000e-02,   1.86700000e-02,\n",
       "          5.96300000e-02,   9.20800000e-03,   1.49100000e+01,\n",
       "          2.65000000e+01,   9.88700000e+01,   5.67700000e+02,\n",
       "          2.09800000e-01,   8.66300000e-01,   6.86900000e-01,\n",
       "          2.57500000e-01,   6.63800000e-01,   1.73000000e-01],\n",
       "       [  2.02900000e+01,   1.43400000e+01,   1.35100000e+02,\n",
       "          1.29700000e+03,   1.00300000e-01,   1.32800000e-01,\n",
       "          1.98000000e-01,   1.04300000e-01,   1.80900000e-01,\n",
       "          5.88300000e-02,   7.57200000e-01,   7.81300000e-01,\n",
       "          5.43800000e+00,   9.44400000e+01,   1.14900000e-02,\n",
       "          2.46100000e-02,   5.68800000e-02,   1.88500000e-02,\n",
       "          1.75600000e-02,   5.11500000e-03,   2.25400000e+01,\n",
       "          1.66700000e+01,   1.52200000e+02,   1.57500000e+03,\n",
       "          1.37400000e-01,   2.05000000e-01,   4.00000000e-01,\n",
       "          1.62500000e-01,   2.36400000e-01,   7.67800000e-02]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data[0:5,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de Regresión Logística "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hipótesis\n",
    "Función Sigmoid:\n",
    "\n",
    "$sig(t) = {\\frac {1} {1 + e^{-t}}}$\n",
    "\n",
    "Combinamos la función sigmoid/lógistica con la  hipótesis conocida (aprendida en regresión lineal) y tenemos la nueva hipótesis para clasificación con regresión lógistica:\n",
    "\n",
    "$z = \\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + \\ldots + \\theta_{n}x_{n}$\n",
    "\n",
    "$g(z) = {\\frac {1} {1 + e^{-z}}}$\n",
    "\n",
    "** Hipótesis para clasificación con regresión logística: **\n",
    "\n",
    "$h_{\\theta}(x) = {\\frac {1} {1 + e^{-(\\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + \\ldots + \\theta_{n}x_{n})}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Sigmoid \n",
    "\n",
    "def sigmoid(z):\n",
    "    ### INICIO: TU CODIGO AQUI:  (~1 linea)###\n",
    "    s = 1/(1 + np.exp(-z))\n",
    "    ### FIN ##\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(0) = 0.5\n",
      "sigmoid(9.2) = 0.999898970806\n"
     ]
    }
   ],
   "source": [
    "### Validando nuestra funcion sigmoid\n",
    "print (\"sigmoid(0) = \" + str(sigmoid(0)))\n",
    "print (\"sigmoid(9.2) = \" + str(sigmoid(9.2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados esperados\n",
    "\n",
    "**sigmoid(0)** = 0.5\n",
    "\n",
    "**sigmoid(9.2)** = 0.999898970806\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementado la hipótesis/modelo para clasificación con regresión logística\n",
    "\n",
    "** Hipótesis para clasificación con regresión logística: **\n",
    "\n",
    "$h_{\\theta}(x) = {\\frac {1} {1 + e^{-(\\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + \\ldots + \\theta_{n}x_{n})}}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hipotesis(features, theta_values):\n",
    "    ## Calculo de la hipotesis de froma vectorizada,producto punto entre el vector de features y el vector de parametros theta ##\n",
    "    z = features.dot(theta_values)\n",
    "    \n",
    "    ### INICIO: TU CODIGO AQUI:  (~1 linea)###\n",
    "    h = sigmoid(z)\n",
    "    ### FIN ##\n",
    "    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas de evaluación\n",
    "\n",
    "Tal como lo vimos en la clase 22: evaluación , utilizamos diversas métricas para evaluar y reportar la exactitud y rendimiento de nuestros modelos de machine learning. En clasificación usamos el costo: cross-entropy para entrenar, pero evaluamos y reportamos diversas métricas mas ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costo\n",
    "\n",
    "El proceso de gradient descent busca minimizar la siguiente función de costo en función de los parámetros theta, y así encontrar los parámetros que producen una hipótesis optima. \n",
    "\n",
    "El costo mide que tan buena o mala es una hipótesis por lo cual esperamos que este disminuya durante el entrenamiento.\n",
    "\n",
    "$J(\\Theta) = - {\\frac {1}{m}}\\sum _{i=1}^{m} y \\log(h(x)) + (1-y)\\log(1-h(x))$\n",
    "\n",
    "Utiliza la funcion log de numpy, Ejemplo:\n",
    "`np.log(y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def costo(X, theta_vector, y):\n",
    "    m = len(y)\n",
    "    \n",
    "    ### INICIO: TU CODIGO AQUI:  (~2 lineas)###\n",
    "    y_hat = get_hipotesis(X, theta_vector)\n",
    "    \n",
    "    costo = -(np.sum(y*(np.log(y_hat))+((1-y)*np.log(1-y_hat))))/m\n",
    "    ### FIN ##\n",
    "    \n",
    "    return costo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Score\n",
    "\n",
    "Implementa la funcion de accuracy utlizando sklearn(puedes utilizar como referencia la clase 22: evaluación )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(X, theta_vector, y):\n",
    "\n",
    "    hipotesis = get_hipotesis(X, theta_vector)\n",
    "    \n",
    "    # Convertimos el resultado probabilistico a deterministico (0 1)\n",
    "    y_pred = [1 if (y >= 0.5) else 0 for y in hipotesis ]\n",
    "    \n",
    "    ### INICIO: TU CODIGO AQUI:  (~1 linea)###\n",
    "    acc_score = accuracy_score(y, y_pred)\n",
    "\n",
    "    ### FIN ##\n",
    "    \n",
    "    return acc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Score\n",
    "\n",
    "Implementa la funcion de f1_score utlizando sklearn(puedes utilizar como referencia la clase 22: evaluación )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1(X, theta_vector, y):\n",
    "\n",
    "    hipotesis = get_hipotesis(X, theta_vector)\n",
    "\n",
    "    # Convertimos el resultado probabilistico a deterministico (0 1)    \n",
    "    y_pred = [1 if (y >= 0.5) else 0 for y in hipotesis ]\n",
    "    \n",
    "    ## INICIO: TU CODIGO AQUI:  (~1 linea)###\n",
    "    f1 = f1_score(y,y_pred)\n",
    "    ### FIN ##\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision Score\n",
    "\n",
    "Implementa la funcion de precision_score utlizando sklearn(puedes utilizar como referencia la clase 22: evaluación )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def precision(X, theta_vector, y):\n",
    "\n",
    "    hipotesis = get_hipotesis(X, theta_vector)\n",
    "\n",
    "    # Convertimos el resultado probabilistico a deterministico (0 1)    \n",
    "    y_pred = [1 if (y >= 0.5) else 0 for y in hipotesis ]\n",
    "    \n",
    "    ## INICIO: TU CODIGO AQUI:  (~1 linea)###\n",
    "    precision = precision_score(y, y_pred)\n",
    "    ### FIN ##\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall Score\n",
    "\n",
    "Implementa la funcion de recall_score utlizando sklearn(puedes utilizar como referencia la clase 22: evaluación )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recall(X, theta_vector, y):\n",
    "\n",
    "    hipotesis = get_hipotesis(X, theta_vector)\n",
    "\n",
    "    # Convertimos el resultado probabilistico a deterministico (0 1)    \n",
    "    y_pred = [1 if (y >= 0.5) else 0 for y in hipotesis ]\n",
    "    \n",
    "    ## INICIO: TU CODIGO AQUI:  (~1 linea)###\n",
    "    reacall = recall_score(y, y_pred)\n",
    "    ### FIN ##\n",
    "    \n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-procesamiento\n",
    "\n",
    "En Machine learning, la fase de pre-procesamiento(incluyendo feature engineering) de datos puede llegar a abarcar el 70% o más del tiempo de un proyecto , pero este es un tema que se profundiza en otros cursos del área de ciencia de datos por lo cual en este proyecto solo vamos a realizar como pre-procesamiento una normalización de features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandarización o Z-score Normalizacion \n",
    "\n",
    "El objetivo de la normalización es ayudar a gradient descent a encontrar el mínimo del costo mas rápido y fácilmente , esto se logra a través de convertir las features de manera que tengan media = 0 y desviación estándar de 1 , similar a una distribución de probabilidad normal(gaussiana).\n",
    "\n",
    "Lo calculamos utilizando:\n",
    "\n",
    "$z = {\\frac {x - \\mu} {\\sigma}}$\n",
    "\n",
    "Donde $\\mu$ es la media y $\\sigma$ es la desviacion estandard\n",
    "\n",
    "##### Comentario opcional:\n",
    "el Z-score en el nombre concuerda con el uso de \"z-scores\" en estadística cuando se hace estadística inferencial(prueba de hipótesis e intervalos de confianza)\n",
    "\n",
    "Implementa la funcion de normalizacion sin utlizar sklearn solo puedes utilizar numpy.\n",
    "\n",
    "Para utilizar la columna de features, utilizamos `features[:,i]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalizar(features):\n",
    "    std = 1\n",
    "    media = 0\n",
    "    \n",
    "    # Utilizamos el ciclo, para normalizar cada feature(una iteracion por feature)\n",
    "    for i in list(range(0, features.shape[1])):\n",
    "        ### INICIO: TU CODIGO AQUI:  (~3 lineas)###\n",
    "        std = features.std()\n",
    "        media = features.mean()\n",
    "        features[:,i] = (i-media)/std\n",
    "        ### FIN ##\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediccion\n",
    "\n",
    "Una vez entrenado, el modelo de ML se utiliza para realizar predicciones ,en este proyecto realizaremos predicciones en un train y un test set(no usaremos cross-validation set)  .Una  vez exportado y entregado el modelo al profesor, el modelo realizara predicciones dentro de una aplicación móvil . \n",
    "\n",
    "La siguiente función la vamos a utilizar para realizar predicciones a lo largo del proyecto(y así poder medir contra los datos reales para realizar evaluación), no hay que cambiar nada del código, solo ejecuta la celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediccion(x, theta_vector, normalizar_valores):\n",
    "    numero_features = x.shape[1] + 1\n",
    "    \n",
    "    if (normalizar_valores):\n",
    "        x = normalizar(x)\n",
    "    \n",
    "    x_features = np.ones((x.shape[0], numero_features))\n",
    "    x_features[:,:-1] = x\n",
    "\n",
    "    \n",
    "    y_hat = get_hipotesis(x_features, theta_vector)\n",
    "    \n",
    "    return np.array([1 if (y >= 0.5) else 0 for y in y_hat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Gradient descent es el algoritmo o método de optimización matemática que nos permite realizar el “entrenamiento” de nuestro modelos, ya que minimiza el costo y nos devuelve los parámetros del modelo óptimos.\n",
    "\n",
    "En la siguiente celda, debes implementar gradient descent tal como visto en clase y practicado en las tareas .\n",
    "\n",
    "Lo definimos e implementamos dentro de una función de Python para que podamos ejecutarlo(“llamarlo”) múltiples veces con distintos parámetros, sin tener que volver a programarlo cada vez , esto nos será útil para experimentar y entrenar varios modelos.\n",
    "\n",
    "Repetir{\n",
    "\n",
    "$\\theta_{j} := \\theta _{j} - \\alpha {\\frac {1}{m}} \\sum _{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})x^{(i)}_{j}$\n",
    "\n",
    "}\n",
    "        \n",
    "Simultaneamente para cada $j = 0,\\ldots,n $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, theta_vector, alpha, iterations, X_test, y_test, nombre_modelo):\n",
    "    global log_book\n",
    "    m = len(y)  #numero de ejemplos de entrenamiento\n",
    "\n",
    "    ## Las siguientes 3 lineas de codigo crean listas vacias para almacenar el costo y accuracy obtenido en cada iteracion\n",
    "    ## Se espera que el costo disminuya y el accuracy aumente\n",
    "    cost_vect = []\n",
    "    accuracy_vect = []\n",
    "    accuracy_vect_test = []\n",
    "    \n",
    "    for iteration in range(iterations):\n",
    "        '''\n",
    "        IMPLELEMTA TU CODIGO AQUI, llama a la funcion para calcular la hipotesis,es decir calcular h(x)\n",
    "        que se implemento mas arriba. Parametros matriz de features X y el vector\n",
    "        con los valores Theta (~1 linea)\n",
    "        '''\n",
    "        hipotesis = get_hipotesis(X, theta_vector)\n",
    "\n",
    "\n",
    "        theta_vector_temp = [] # vector que guarda los parametros theta temporales\n",
    "        \n",
    "        # Utilizamos un ciclo para realizar la actualizacion de gradient descent una vez para cada parametro\n",
    "        # En cada iteracion \"i\" guarda el numero de parametro theta, y la varaible \"theta\" guarda el parametro como tal\n",
    "        for i, theta in enumerate(theta_vector):\n",
    "            '''\n",
    "            IMPLELEMTA TU CODIGO AQUI, adentro de este ciclo vamos a calcular\n",
    "            elnuevo valor de Theta[i], utilizando la formula de la celda de arriba\n",
    "            Recuerda que para multiplicar por utilizamos X[:,i]  (~1 linea)\n",
    "            '''\n",
    "            nuevo_theta =  theta - ((alpha/m)*np.sum(np.subtract(hipotesis,y)*X[:,i]))\n",
    "\n",
    "            ### aqui agregamos el nuevo valor the theta[i] a un vector temporal\n",
    "            theta_vector_temp.append(nuevo_theta)\n",
    "\n",
    "\n",
    "        ## Actualizamos el vector theta con los nuevos valores\n",
    "        theta_vector = theta_vector_temp\n",
    "\n",
    "        # En las sigiuentes lineas calculamos las metricas de evaluacion en cada iteracion(aplicadas al train-set)\n",
    "        '''\n",
    "        IMPLEMENTA TU CODIGO AQUI, llama a la funcion de costo (~1 linea)\n",
    "        '''\n",
    "        cost = costo(X, theta_vector, y)\n",
    "        \n",
    "        '''\n",
    "        IMPLEMENTA TU CODIGO AQUI, utiliza Accuracy que se definio arriba (~1 linea)\n",
    "        '''\n",
    "        acc_score = accuracy(X, theta_vector, y)\n",
    "        \n",
    "        '''\n",
    "        IMPLEMENTA TU CODIGO AQUI, utiliza f1 score que se definio arriba (~1 linea)\n",
    "        '''\n",
    "        f1_training = f1(X, theta_vector, y)\n",
    "\n",
    "        '''\n",
    "        IMPLEMENTA TU CODIGO AQUI, utiliza precision score que se definio arriba (~1 linea)\n",
    "        '''\n",
    "        precision_training = precision(X, theta_vector, y)\n",
    "        \n",
    "        '''\n",
    "        IMPLEMENTA TU CODIGO AQUI, utiliza recall score que se definio arriba (~1 linea)\n",
    "        '''\n",
    "        recall_training = recall(X, theta_vector, y)\n",
    "        \n",
    "        \n",
    "        ## En las siguientes lineas calculamos las metricas de evaluacion aplicadas al test-set, este codigo no hay que cambiarlo ####\n",
    "        y_predict = prediccion(X_test, theta_vector, True)\n",
    "        acc_test = accuracy_score(y_predict, y_test)\n",
    "        accuracy_vect_test.append(acc_test)\n",
    "        f1_score_test = f1_score(y_predict, y_test)\n",
    "        precision_test = precision_score(y_test, y_predict)\n",
    "        recall_test = recall_score(y_test, y_predict)\n",
    "        \n",
    "        ## Guardando el valor del costo para graficarlo, este codigo no hay que cambiarlo ##\n",
    "        cost_vect.append(cost)\n",
    "        accuracy_vect.append(acc_score)\n",
    "        \n",
    "        n = 50 ### Ingresa aqui cada cuantas iteraciones quieres que se imprima el valor de las metricas ###\n",
    "        \n",
    "        ## Este codigo no hay que modificarlo ##\n",
    "        if(iteration % n == 0):\n",
    "            print('#####################')\n",
    "            print('TRAINING: [Iteracion: ', iteration,' Costo: ', cost, \\\n",
    "                  ' Accuracy:', acc_score,' F1 Score:',f1_training, \\\n",
    "                  'Precision training:', precision_training, 'Recall training:', recall_training,']')\n",
    "            print('TEST: [Iteracion: ', iteration,'Accuracy:', acc_test, \\\n",
    "                  ' F1 Score:', f1_score_test, 'Precision Test:', precision_test,'Recall Test:', recall_test,']')\n",
    "        \n",
    "    ## Log book, este codigo no hay que cambiarlo, sirve para guardar en la bitacora los resultados del experimento ##\n",
    "    nombre_modelo = nombre_modelo + '_'+datetime.datetime.now().strftime(\"%d%H%M%f\")\n",
    "    numero_features = X.shape[1] - 1\n",
    "    experiment = np.array([nombre_modelo, numero_features, m, alpha, iterations, accuracy_vect[-1], \\\n",
    "                           accuracy_vect_test[-1], f1_score_test, precision_test, \\\n",
    "                           recall_test,theta_vector], dtype=object)\n",
    "    log_book = np.vstack([log_book, experiment])\n",
    "        \n",
    "    return theta_vector, cost_vect, accuracy_vect,accuracy_vect_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividimos la data en training y test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal como visto en la clase 23, nos sirve para evaluar objetivamente el rendimiento de nuestros modelos en datos que nunca ha visto durante su entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, stratify=data.target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 30)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento\n",
    "\n",
    "## Features a utilizar\n",
    "A continuación, vamos a entrenar varios modelos, vamos a utilizar las funciones que creamos previamente.\n",
    "Es importante experimentar con diferentes features,diverso tamaño del training set, y diversos hyper-parametros(learning rate e iteraciones)\n",
    "\n",
    "En este proyecto como máximo vamos a utilizar 5 features(pero en algunos experimentos usaremos menos) de manera obligatoria, pero de forma opcional se recomienda experimentar con más y diversas combinaciones ,esto para practicar y obtener experiencia con ML. \n",
    "\n",
    "También vamos a utilizar diferente número de ejemplos en el set de datos, diferente número de iteraciones y diferente learning rate . Todas estas distintas configuraciones serán almacenadas en el log-book(bitácora) automáticamente .\n",
    "\n",
    "En este proyecto solo vamos a utilizar las primeras 5 features  en este orden:\n",
    "\n",
    "`['mean radius', 'mean texture', 'mean perimeter', 'mean area','mean smoothness']`\n",
    "\n",
    "La razón por las que usaremos estas 5 features específicamente(y en este orden) en el modelo final(el que será exportado) es que estas features son las que serán utilizadas en la aplicación móvil en la cual integraremos el modelo(y tendremos en la interfaz de usuario de la aplicación componentes para ingresar valores para estas features),ero como se mencionó se recomienda experimentar y evaluar resultados con distintas features y distinto número  de ellas .\n",
    "\n",
    "## Descripcion del entrenamiento\n",
    "El entrenamiento de cada modelo se compone básicamente de tres pasos, sampleo bootstrap, escoger las features y ejecutar el entrenamiento llamando a la función de gradient descent que ya creamos.\n",
    "\n",
    "En el primer paso vamos a utilizar la función resample para hacer un sampleo del set de datos de entrenamiento, debemos definir el numero de samples que queremos utilizar.\n",
    "\n",
    "En el segundo paso, en un arreglo vamos a definir el nombre de las features que queremos utilizar para entrenar el modelo.\n",
    "En el tercer paso ejecutamos la función gradient descent.\n",
    "\n",
    "Por ultimo vamos a obtener el accuracy del modelo y vamos a imprimir la matriz de confusión, imprimiremos el precisión y el recall del modelo para entender mejor los resultados y tener una mejor idea de que tan bien clasifica nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento modelo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampleo bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m1, Y_train_m1 = resample(X_train, y_train, n_samples = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar Features\n",
    "Solo seleccionar los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Ingresa en la lista el nombre de las fatrues que quieres utlizar en este modelo (~1 linea)\n",
    "'''\n",
    "features_filtro = ['mean radius', 'mean texture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_m1 = helper.fitrar_nombre(X_train_m1,data.feature_names,features_filtro)\n",
    "X_test_features = helper.fitrar_nombre(X_test,data.feature_names,features_filtro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_m1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 2)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numero de iteracions ##\n",
    "iterations = 500  # Define el numero de iteraciones #\n",
    "\n",
    "## Alpha ##\n",
    "alpha = 0.1 # Define el valor de alpha #\n",
    "\n",
    "#### No hay que cambiar el codigo despues de esta linea #####\n",
    "## Numero de feautres ##\n",
    "numero_features = X_train_m1.shape[1] + 1\n",
    "\n",
    "## Creamos un vector donde se almacenan los valores de Theta,\n",
    "## lo inicializamos con numeros aleatorios\n",
    "theta_vector = np.random.rand(numero_features)\n",
    "\n",
    "## Normaliza las features de X_train_features (~1 linea) ##\n",
    "X_train_m1 = normalizar(X_train_m1)\n",
    "\n",
    "# Creando la Matriz X de features, \n",
    "# utilizamos np.ones para agregar el valor constante '1' que es el bias o feature 0\n",
    "X_train_features = np.ones((X_train_m1.shape[0], numero_features))\n",
    "X_train_features[:,:-1] = X_train_m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isa Miranda\\Documents\\UFM\\7mo SEMESTRE\\Machine_Learning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Isa Miranda\\Documents\\UFM\\7mo SEMESTRE\\Machine_Learning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Isa Miranda\\Documents\\UFM\\7mo SEMESTRE\\Machine_Learning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "TRAINING: [Iteracion:  0  Costo:  1.30248850243  Accuracy: 0.38  F1 Score: 0.0 Precision training: 0.0 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  0 Accuracy: 0.370629370629  F1 Score: 0.0 Precision Test: 0.0 Recall Test: 0.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  50  Costo:  0.664064126564  Accuracy: 0.62  F1 Score: 0.765432098765 Precision training: 0.62 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  50 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  100  Costo:  0.664064126564  Accuracy: 0.62  F1 Score: 0.765432098765 Precision training: 0.62 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  100 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  150  Costo:  0.664064126564  Accuracy: 0.62  F1 Score: 0.765432098765 Precision training: 0.62 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  150 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  200  Costo:  0.664064126564  Accuracy: 0.62  F1 Score: 0.765432098765 Precision training: 0.62 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  200 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  250  Costo:  0.664064126564  Accuracy: 0.62  F1 Score: 0.765432098765 Precision training: 0.62 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  250 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  300  Costo:  0.664064126564  Accuracy: 0.62  F1 Score: 0.765432098765 Precision training: 0.62 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  300 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  350  Costo:  0.664064126564  Accuracy: 0.62  F1 Score: 0.765432098765 Precision training: 0.62 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  350 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  400  Costo:  0.664064126564  Accuracy: 0.62  F1 Score: 0.765432098765 Precision training: 0.62 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  400 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  450  Costo:  0.664064126564  Accuracy: 0.62  F1 Score: 0.765432098765 Precision training: 0.62 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  450 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n"
     ]
    }
   ],
   "source": [
    "modelo_1_theta_values, cost_vect, acc_vect, acc_vect_test = \\\n",
    "gradient_descent(X_train_features, Y_train_m1, theta_vector, alpha, iterations, X_test_features, y_test, 'modelo_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c04d06f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Funcion para graficar el costo y  accuracy durante cada iteracion ##\n",
    "helper.training_graph(cost_vect, acc_vect, acc_vect_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy y Matriz de confusion Training Set\n",
    "\n",
    "![alt text](https://rasbt.github.io/mlxtend/user_guide/evaluate/confusion_matrix_files/confusion_matrix_1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.0 %\n",
      "\n",
      "Matriz de confusion\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0, 57],\n",
       "       [ 0, 93]], dtype=int64)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = get_hipotesis(X_train_features, modelo_1_theta_values)\n",
    "y_predict = np.array([1 if (y > 0.5) else 0 for y in y_hat])\n",
    "\n",
    "print('Accuracy:', accuracy_score(Y_train_m1,y_predict) * 100 ,'%')\n",
    "print()\n",
    "print('Matriz de confusion')\n",
    "confusion_matrix(Y_train_m1, y_predict )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy con el Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = prediccion(X_test_features, modelo_1_theta_values, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.9370629371 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:',accuracy_score(y_test, y_predict)* 100 ,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusion Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 53],\n",
       "       [ 0, 90]], dtype=int64)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.629370629371\n",
      "recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('precision: ',precision_score(y_test, y_predict))\n",
    "\n",
    "print('recall: ', recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento modelo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampleo bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Ingresa en la lista el nombre de las fatrues que quieres utlizar en este modelo (~1 linea)\n",
    "'''\n",
    "X_train_m2, Y_train_m2 = resample(X_train, y_train, n_samples = 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar Features\n",
    "Solo seleccionar los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_filtro = ['mean perimeter', 'mean area','mean smoothness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m2 = helper.fitrar_nombre(X_train_m2,data.feature_names,features_filtro)\n",
    "X_test_features = helper.fitrar_nombre(X_test,data.feature_names,features_filtro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Numero de iteracions ##\n",
    "iterations = 1000  # Define el numero de iteraciones #\n",
    "\n",
    "## Alpha ##\n",
    "alpha = 0.05 # Define el valor de alpha #\n",
    "\n",
    "#### No hay que cambiar el codigo despues de esta linea #####\n",
    "## Numero de feautres ##\n",
    "numero_features = X_train_m2.shape[1] + 1\n",
    "\n",
    "## Creamos un vector donde se almacenan los valores de Theta,\n",
    "## lo inicializamos con numeros aleatorios\n",
    "theta_vector = np.random.rand(numero_features)\n",
    "\n",
    "## Normaliza las features de X_train_features (~1 linea) ##\n",
    "X_train_m2 = normalizar(X_train_m2)\n",
    "\n",
    "# Creando la Matriz X de features, \n",
    "# utilizamos np.ones para agregar el valor constante '1' que es el bias o feature 0\n",
    "X_train_features = np.ones((X_train_m2.shape[0], numero_features))\n",
    "X_train_features[:,:-1] = X_train_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "TRAINING: [Iteracion:  0  Costo:  0.678932094359  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  0 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isa Miranda\\Documents\\UFM\\7mo SEMESTRE\\Machine_Learning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Isa Miranda\\Documents\\UFM\\7mo SEMESTRE\\Machine_Learning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "TRAINING: [Iteracion:  50  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  50 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  100  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  100 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  150  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  150 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  200  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  200 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  250  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  250 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  300  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  300 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  350  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  350 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  400  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  400 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  450  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  450 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  500  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  500 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  550  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  550 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  600  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  600 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  650  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  650 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  700  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  700 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  750  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  750 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  800  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  800 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  850  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  850 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  900  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  900 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  950  Costo:  0.678626762456  Accuracy: 0.585  F1 Score: 0.738170347003 Precision training: 0.585 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  950 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n"
     ]
    }
   ],
   "source": [
    "## Llama a la funcion de gradient descent, recurda definir un nombre diferente para el modelo (~1 linea) ##\n",
    "modelo_2_theta_values, cost_vect, acc_vect, acc_vect_test = \\\n",
    "gradient_descent(X_train_features, Y_train_m2, theta_vector, alpha, iterations, X_test_features, y_test, 'modelo_2')\n",
    "### FIN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/++F/R9ivq5IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c0506a4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Funcion para graficar el costo y  accuracy durante cada iteracion ##\n",
    "helper.training_graph(cost_vect, acc_vect, acc_vect_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy con el Test set [Modelo 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = prediccion(X_test_features, modelo_2_theta_values, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.9370629371 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:',accuracy_score(y_test, y_predict)* 100 ,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusion Test Set [Modelo 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 53],\n",
       "       [ 0, 90]], dtype=int64)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.629370629371\n",
      "recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('precision: ',precision_score(y_test, y_predict))\n",
    "\n",
    "print('recall: ', recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento modelo 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampleo bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m3, Y_train_m3 = resample(X_train, y_train, n_samples = 460)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar Features\n",
    "Solo seleccionar los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Ingresa en la lista el nombre de las fatrues que quieres utlizar en este modelo (~1 linea)\n",
    "'''\n",
    "features_filtro = ['mean radius', 'mean texture', 'mean perimeter', 'mean area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m3 = helper.fitrar_nombre(X_train_m3,data.feature_names,features_filtro)\n",
    "X_test_features = helper.fitrar_nombre(X_test,data.feature_names,features_filtro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Numero de iteracions ##\n",
    "iterations = 1500  # Define el numero de iteraciones #\n",
    "\n",
    "## Alpha ##\n",
    "alpha = 0.02 # Define el valor de alpha #\n",
    "\n",
    "#### No hay que cambiar el codigo despues de esta linea #####\n",
    "## Numero de feautres ##\n",
    "numero_features = X_train_m3.shape[1] + 1\n",
    "\n",
    "## Creamos un vector donde se almacenan los valores de Theta,\n",
    "## lo inicializamos con numeros aleatorios\n",
    "theta_vector = np.random.rand(numero_features)\n",
    "\n",
    "## Normaliza las features de X_train_features (~1 linea) ##\n",
    "X_train_m3 = normalizar(X_train_m3)\n",
    "\n",
    "# Creando la Matriz X de features, \n",
    "# utilizamos np.ones para agregar el valor constante '1' que es el bias o feature 0\n",
    "X_train_features = np.ones((X_train_m3.shape[0], numero_features))\n",
    "X_train_features[:,:-1] = X_train_m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isa Miranda\\Documents\\UFM\\7mo SEMESTRE\\Machine_Learning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Isa Miranda\\Documents\\UFM\\7mo SEMESTRE\\Machine_Learning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Isa Miranda\\Documents\\UFM\\7mo SEMESTRE\\Machine_Learning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "TRAINING: [Iteracion:  0  Costo:  0.764786976812  Accuracy: 0.360869565217  F1 Score: 0.0 Precision training: 0.0 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  0 Accuracy: 0.370629370629  F1 Score: 0.0 Precision Test: 0.0 Recall Test: 0.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  50  Costo:  0.68913997019  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  50 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  100  Costo:  0.665281357695  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  100 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  150  Costo:  0.657662050168  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  150 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  200  Costo:  0.655170658888  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  200 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  250  Costo:  0.654340885605  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  250 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  300  Costo:  0.654061162019  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  300 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  350  Costo:  0.653966156464  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  350 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  400  Costo:  0.653933742794  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  400 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  450  Costo:  0.653922654278  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  450 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  500  Costo:  0.653918854941  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  500 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  550  Costo:  0.653917551929  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  550 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  600  Costo:  0.653917104806  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  600 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  650  Costo:  0.653916951328  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  650 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  700  Costo:  0.653916898636  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  700 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  750  Costo:  0.653916880543  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  750 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  800  Costo:  0.653916874331  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  800 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  850  Costo:  0.653916872197  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  850 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  900  Costo:  0.653916871465  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  900 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  950  Costo:  0.653916871213  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  950 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1000  Costo:  0.653916871127  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1000 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1050  Costo:  0.653916871097  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1050 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1100  Costo:  0.653916871087  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1100 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1150  Costo:  0.653916871083  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1150 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1200  Costo:  0.653916871082  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1200 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "TRAINING: [Iteracion:  1250  Costo:  0.653916871082  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1250 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1300  Costo:  0.653916871082  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1300 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1350  Costo:  0.653916871082  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1350 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1400  Costo:  0.653916871082  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1400 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1450  Costo:  0.653916871081  Accuracy: 0.639130434783  F1 Score: 0.779840848806 Precision training: 0.639130434783 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1450 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n"
     ]
    }
   ],
   "source": [
    "## Llama a la funcion de gradient descent, recurda definir un nombre diferente para el modelo (~1 linea) ##\n",
    "modelo_3_theta_values, cost_vect, acc_vect, acc_vect_test = \\\n",
    "gradient_descent(X_train_features, Y_train_m3, theta_vector, alpha, iterations, X_test_features, y_test, 'modelo_3')\n",
    "### FIN ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c04ddb2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Funcion para graficar el costo y  accuracy durante cada iteracion\n",
    "helper.training_graph(cost_vect, acc_vect, acc_vect_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy con el Test set [Modelo 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = prediccion(X_test_features, modelo_3_theta_values, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.9370629371 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:',accuracy_score(y_test, y_predict)* 100 ,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusion Test Set [Modelo 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 53],\n",
       "       [ 0, 90]], dtype=int64)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.629370629371\n",
      "recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('precision: ',precision_score(y_test, y_predict))\n",
    "\n",
    "print('recall: ', recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento modelo 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampleo bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m4, Y_train_m4 = resample(X_train, y_train, n_samples = 460)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar Features\n",
    "Solo seleccionar los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Ingresa en la lista el nombre de las fatrues que quieres utlizar en este modelo (~1 linea)\n",
    "'''\n",
    "features_filtro = ['mean radius', 'mean texture', 'mean perimeter', 'mean area','mean smoothness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m4 = helper.fitrar_nombre(X_train_m4,data.feature_names,features_filtro)\n",
    "X_test_features = helper.fitrar_nombre(X_test,data.feature_names,features_filtro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Numero de iteracions ##\n",
    "iterations = 1000 # Define el numero de iteraciones #\n",
    "\n",
    "## Alpha ##\n",
    "alpha = 0.03 # Define el valor de alpha #\n",
    "\n",
    "#### No hay que cambiar el codigo despues de esta linea #####\n",
    "## Numero de feautres ##\n",
    "numero_features = X_train_m4.shape[1] + 1\n",
    "\n",
    "## Creamos un vector donde se almacenan los valores de Theta,\n",
    "## lo inicializamos con numeros aleatorios\n",
    "theta_vector = np.random.rand(numero_features)\n",
    "\n",
    "## Normaliza las features de X_train_features (~1 linea) ##\n",
    "X_train_m4 = normalizar(X_train_m4)\n",
    "\n",
    "# Creando la Matriz X de features\n",
    "X_train_features = np.ones((X_train_m4.shape[0], numero_features))\n",
    "X_train_features[:,:-1] = X_train_m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "TRAINING: [Iteracion:  0  Costo:  3.74676321188  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  0 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isa Miranda\\Documents\\UFM\\7mo SEMESTRE\\Machine_Learning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Isa Miranda\\Documents\\UFM\\7mo SEMESTRE\\Machine_Learning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Isa Miranda\\Documents\\UFM\\7mo SEMESTRE\\Machine_Learning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "TRAINING: [Iteracion:  50  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  50 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  100  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  100 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  150  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  150 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  200  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  200 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  250  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  250 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  300  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  300 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  350  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  350 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  400  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  400 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  450  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  450 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  500  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  500 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  550  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  550 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  600  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  600 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  650  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  650 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  700  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  700 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  750  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  750 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  800  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  800 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  850  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  850 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  900  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  900 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  950  Costo:  1.05410725009  Accuracy: 0.610869565217  F1 Score: 0.758434547908 Precision training: 0.610869565217 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  950 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n"
     ]
    }
   ],
   "source": [
    "## Llama a la funcion de gradient descent, recurda definir un nombre diferente para el modelo (~1 linea) ##\n",
    "modelo_4_theta_values, cost_vect, acc_vect, acc_vect_test = \\\n",
    "gradient_descent(X_train_features, Y_train_m4, theta_vector, alpha, iterations, X_test_features, y_test, 'modelo_4')\n",
    "### FIN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c04e24240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Funcion para graficar el costo y  accuracy durante cada iteracion ##\n",
    "helper.training_graph(cost_vect, acc_vect, acc_vect_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy con el Test set [Modelo 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = prediccion(X_test_features, modelo_4_theta_values, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.9370629371 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:',accuracy_score(y_test, y_predict)* 100 ,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusion Test Set [Modelo 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 53],\n",
       "       [ 0, 90]], dtype=int64)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.629370629371\n",
      "recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('precision: ',precision_score(y_test, y_predict))\n",
    "\n",
    "print('recall: ', recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento modelo 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampleo bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m5, Y_train_m5 = resample(X_train, y_train, n_samples = 460)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar Features\n",
    "Solo seleccionar los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Ingresa en la lista el nombre de las fatrues que quieres utlizar en este modelo (~1 linea)\n",
    "'''\n",
    "features_filtro = ['mean radius', 'mean texture', 'mean perimeter', 'mean area','mean smoothness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_m5 = helper.fitrar_nombre(X_train_m5,data.feature_names,features_filtro)\n",
    "X_test_features = helper.fitrar_nombre(X_test,data.feature_names,features_filtro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Numero de iteracions ##\n",
    "iterations = 2000 # Define el numero de iteraciones #\n",
    "\n",
    "## Alpha ##\n",
    "alpha = 0.01 # Define el valor de alpha #\n",
    "\n",
    "#### No hay que cambiar el codigo despues de esta linea #####\n",
    "## Numero de feautres ##\n",
    "numero_features = X_train_m5.shape[1] + 1\n",
    "\n",
    "## Creamos un vector donde se almacenan los valores de Theta,\n",
    "## lo inicializamos con numeros aleatorios\n",
    "theta_vector = np.random.rand(numero_features)\n",
    "\n",
    "## Normaliza las features de X_train_features (~1 linea) ##\n",
    "X_train_m5 = normalizar(X_train_m5)\n",
    "\n",
    "# Creando la Matriz X de features\n",
    "X_train_features = np.ones((X_train_m5.shape[0], numero_features))\n",
    "X_train_features[:,:-1] = X_train_m5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "TRAINING: [Iteracion:  0  Costo:  2.32656297438  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  0 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Isa Miranda\\Documents\\UFM\\7mo SEMESTRE\\Machine_Learning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\Isa Miranda\\Documents\\UFM\\7mo SEMESTRE\\Machine_Learning\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "TRAINING: [Iteracion:  50  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  50 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  100  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  100 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  150  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  150 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  200  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  200 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  250  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  250 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  300  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  300 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  350  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  350 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  400  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  400 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  450  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  450 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  500  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  500 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  550  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  550 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  600  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  600 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  650  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  650 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  700  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  700 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  750  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  750 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  800  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  800 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  850  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  850 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  900  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  900 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  950  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  950 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1000  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1000 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1050  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1050 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1100  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1100 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1150  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1150 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1200  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1200 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "TRAINING: [Iteracion:  1250  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1250 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1300  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1300 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1350  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1350 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1400  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1400 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1450  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1450 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1500  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1500 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1550  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1550 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1600  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1600 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1650  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1650 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1700  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1700 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1750  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1750 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1800  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1800 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1850  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1850 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1900  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1900 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n",
      "#####################\n",
      "TRAINING: [Iteracion:  1950  Costo:  0.650096646101  Accuracy: 0.645652173913  F1 Score: 0.784676354029 Precision training: 0.645652173913 Recall training: <function recall at 0x0000022C044946A8> ]\n",
      "TEST: [Iteracion:  1950 Accuracy: 0.629370629371  F1 Score: 0.772532188841 Precision Test: 0.629370629371 Recall Test: 1.0 ]\n"
     ]
    }
   ],
   "source": [
    "## Llama a la funcion de gradient descent, recurda definir un nombre diferente para el modelo (~1 linea) ##\n",
    "modelo_5_theta_values, cost_vect, acc_vect, acc_vect_test = \\\n",
    "gradient_descent(X_train_features, Y_train_m5, theta_vector, alpha, iterations, X_test_features, y_test, 'modelo_5')\n",
    "### FIN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYv4/+LDBY4Ph9ToAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c04d3a208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Funcion para graficar el costo y  accuracy durante cada iteracion ##\n",
    "helper.training_graph(cost_vect, acc_vect, acc_vect_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy con el Test set [Modelo 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = prediccion(X_test_features, modelo_5_theta_values, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.9370629371 %\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:',accuracy_score(y_test, y_predict)* 100 ,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matriz de confusion Test Set [Modelo 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 53],\n",
       "       [ 0, 90]], dtype=int64)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.629370629371\n",
      "recall:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('precision: ',precision_score(y_test, y_predict))\n",
    "\n",
    "print('recall: ', recall_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparacion de Modelos\n",
    "Es importante llevar un registro de los resultados de nuestros modelos y los hyperparametros que utilizamos, para ir comparando y ajustando los modelos. En nuestra función de gradient descent esta implementado un registro a bitacora, que almacena cada ejecucion de la funcion.\n",
    "\n",
    "Este registro almacena datos que nos van a servir para comprar los modelos y tambien almacena los valores theta del modelo, por lo que podemos guardar los modelos y utlizarlos despues.\n",
    "A continuacion vamos a desplegar en la siguiente celda y nos va ayudar a tomar una decisión de cual es el mejor modelo.\n",
    "\n",
    "Es recomendable que, luego de analizar los resultados del registro ejecutemos de nuevo alguno de los modelos cambiando los hyperparametros o numero de ejemplos y ver con cuales obtenemos mejores resultados.\n",
    "\n",
    "Podemos ejecutar la funcion `helper.guardar_log_book(log_book)` para almacenar en disco los modelos.\n",
    "\n",
    "Para el ultimo paso donde exportamos el modelo debemos utilizar la funcion `helper.filter_log_book(log_book, nombre_modelo)` para obtener el mejor modelo y exportalo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre Modelo</th>\n",
       "      <th>Numero de features</th>\n",
       "      <th>Numero de ejemplos</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Numero de Iteraciones</th>\n",
       "      <th>Accuracy Training</th>\n",
       "      <th>Accuracy Test</th>\n",
       "      <th>F1 score Test</th>\n",
       "      <th>Precision Test</th>\n",
       "      <th>Recall Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modelo_1_011042024717</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.010</td>\n",
       "      <td>500</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>modelo_1_011046782958</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.010</td>\n",
       "      <td>500</td>\n",
       "      <td>0.626667</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>modelo_1_011047574328</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.010</td>\n",
       "      <td>500</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>modelo_1_011050700359</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.010</td>\n",
       "      <td>500</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>modelo_1_011052876559</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.020</td>\n",
       "      <td>500</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>modelo_1_011053632845</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.015</td>\n",
       "      <td>500</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.370629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>modelo_1_011053462149</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>modelo_1_011054156147</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.008</td>\n",
       "      <td>500</td>\n",
       "      <td>0.606667</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>modelo_2_011102996735</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>0.050</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>modelo_2_011103679824</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>0.030</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.595000</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>modelo_2_011106007420</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>0.050</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>modelo_3_011108487691</td>\n",
       "      <td>4</td>\n",
       "      <td>460</td>\n",
       "      <td>0.020</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.656522</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>modelo_4_011109785028</td>\n",
       "      <td>5</td>\n",
       "      <td>460</td>\n",
       "      <td>0.030</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.621739</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>modelo_5_011110934484</td>\n",
       "      <td>5</td>\n",
       "      <td>460</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.634783</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>modelo_1_011114290945</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>modelo_1_011116577754</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>modelo_1_011117331633</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>modelo_1_011118116244</td>\n",
       "      <td>3</td>\n",
       "      <td>150</td>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>modelo_1_011119350786</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.050</td>\n",
       "      <td>500</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>modelo_1_011119692655</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.005</td>\n",
       "      <td>500</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.370629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>modelo_1_011120352544</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>0.050</td>\n",
       "      <td>500</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>modelo_2_011121930499</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>modelo_2_011121623945</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>0.008</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>modelo_2_011122819286</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.662500</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>modelo_5_011126781571</td>\n",
       "      <td>5</td>\n",
       "      <td>460</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.632609</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>modelo_1_011130490569</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0.100</td>\n",
       "      <td>500</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>modelo_2_011131925770</td>\n",
       "      <td>3</td>\n",
       "      <td>400</td>\n",
       "      <td>0.050</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>0.370629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>modelo_3_011131636304</td>\n",
       "      <td>4</td>\n",
       "      <td>460</td>\n",
       "      <td>0.020</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.639130</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>modelo_4_011132112945</td>\n",
       "      <td>5</td>\n",
       "      <td>460</td>\n",
       "      <td>0.030</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.389130</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>modelo_5_011132201623</td>\n",
       "      <td>5</td>\n",
       "      <td>460</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.645652</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.629371</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Nombre Modelo Numero de features Numero de ejemplos  Alpha  \\\n",
       "0   modelo_1_011042024717                  5                150  0.010   \n",
       "1   modelo_1_011046782958                  5                150  0.010   \n",
       "2   modelo_1_011047574328                  5                150  0.010   \n",
       "3   modelo_1_011050700359                  5                150  0.010   \n",
       "4   modelo_1_011052876559                  5                150  0.020   \n",
       "5   modelo_1_011053632845                  5                150  0.015   \n",
       "6   modelo_1_011053462149                  5                150  0.005   \n",
       "7   modelo_1_011054156147                  5                150  0.008   \n",
       "8   modelo_2_011102996735                  3                400  0.050   \n",
       "9   modelo_2_011103679824                  3                400  0.030   \n",
       "10  modelo_2_011106007420                  3                400  0.050   \n",
       "11  modelo_3_011108487691                  4                460  0.020   \n",
       "12  modelo_4_011109785028                  5                460  0.030   \n",
       "13  modelo_5_011110934484                  5                460  0.005   \n",
       "14  modelo_1_011114290945                  3                150  0.100   \n",
       "15  modelo_1_011116577754                  4                150  0.100   \n",
       "16  modelo_1_011117331633                  2                150  0.100   \n",
       "17  modelo_1_011118116244                  3                150  0.100   \n",
       "18  modelo_1_011119350786                  5                150  0.050   \n",
       "19  modelo_1_011119692655                  5                150  0.005   \n",
       "20  modelo_1_011120352544                  5                150  0.050   \n",
       "21  modelo_2_011121930499                  3                400  0.005   \n",
       "22  modelo_2_011121623945                  3                400  0.008   \n",
       "23  modelo_2_011122819286                  3                400  0.005   \n",
       "24  modelo_5_011126781571                  5                460  0.010   \n",
       "25  modelo_1_011130490569                  2                150  0.100   \n",
       "26  modelo_2_011131925770                  3                400  0.050   \n",
       "27  modelo_3_011131636304                  4                460  0.020   \n",
       "28  modelo_4_011132112945                  5                460  0.030   \n",
       "29  modelo_5_011132201623                  5                460  0.010   \n",
       "\n",
       "   Numero de Iteraciones  Accuracy Training  Accuracy Test  F1 score Test  \\\n",
       "0                    500           0.626667       0.629371       0.772532   \n",
       "1                    500           0.626667       0.629371       0.772532   \n",
       "2                    500           0.733333       0.629371       0.772532   \n",
       "3                    500           0.606667       0.629371       0.772532   \n",
       "4                    500           0.606667       0.629371       0.772532   \n",
       "5                    500           0.606667       0.370629       0.000000   \n",
       "6                    500           0.606667       0.629371       0.772532   \n",
       "7                    500           0.606667       0.629371       0.772532   \n",
       "8                   1000           0.595000       0.629371       0.772532   \n",
       "9                   1000           0.595000       0.629371       0.772532   \n",
       "10                  1000           0.675000       0.629371       0.772532   \n",
       "11                  1500           0.656522       0.629371       0.772532   \n",
       "12                  1000           0.621739       0.629371       0.772532   \n",
       "13                  2000           0.634783       0.629371       0.772532   \n",
       "14                   500           0.686667       0.629371       0.772532   \n",
       "15                   500           0.600000       0.629371       0.772532   \n",
       "16                   500           0.600000       0.629371       0.772532   \n",
       "17                   500           0.653333       0.629371       0.772532   \n",
       "18                   500           0.573333       0.629371       0.772532   \n",
       "19                   500           0.573333       0.370629       0.000000   \n",
       "20                   500           0.573333       0.629371       0.772532   \n",
       "21                  1000           0.662500       0.629371       0.772532   \n",
       "22                  1000           0.662500       0.629371       0.772532   \n",
       "23                  1000           0.662500       0.629371       0.772532   \n",
       "24                  2000           0.632609       0.629371       0.772532   \n",
       "25                   500           0.620000       0.629371       0.772532   \n",
       "26                  1000           0.585000       0.370629       0.000000   \n",
       "27                  1500           0.639130       0.629371       0.772532   \n",
       "28                  1000           0.389130       0.629371       0.772532   \n",
       "29                  2000           0.645652       0.629371       0.772532   \n",
       "\n",
       "    Precision Test  Recall Test  \n",
       "0         0.629371          1.0  \n",
       "1         0.629371          1.0  \n",
       "2         0.629371          1.0  \n",
       "3         0.629371          1.0  \n",
       "4         0.629371          1.0  \n",
       "5         0.000000          0.0  \n",
       "6         0.629371          1.0  \n",
       "7         0.629371          1.0  \n",
       "8         0.629371          1.0  \n",
       "9         0.629371          1.0  \n",
       "10        0.629371          1.0  \n",
       "11        0.629371          1.0  \n",
       "12        0.629371          1.0  \n",
       "13        0.629371          1.0  \n",
       "14        0.629371          1.0  \n",
       "15        0.629371          1.0  \n",
       "16        0.629371          1.0  \n",
       "17        0.629371          1.0  \n",
       "18        0.629371          1.0  \n",
       "19        0.000000          0.0  \n",
       "20        0.629371          1.0  \n",
       "21        0.629371          1.0  \n",
       "22        0.629371          1.0  \n",
       "23        0.629371          1.0  \n",
       "24        0.629371          1.0  \n",
       "25        0.629371          1.0  \n",
       "26        0.000000          0.0  \n",
       "27        0.629371          1.0  \n",
       "28        0.629371          1.0  \n",
       "29        0.629371          1.0  "
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper.print_log_book(log_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardando la bitacora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helper.guardar_log_book(log_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportar el modelo\n",
    "\n",
    "Vamos a exportar el modelo para poder hacer deploy, ** el modelo exportado debe tener las cinco primeras feautures **. Por lo cual de todos tus experimentos, selecciona el mejor modelo que cumpla con usar las 5 features ya mencionadas.\n",
    "\n",
    "Selecciona tu mejor modelo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionamos el mejor modelo\n",
    "\n",
    "Para seleccionar un modelo utilizamos la funcion `helper.filter_log_book()`.\n",
    "\n",
    "Esta funcion recibe de parametros la bitacora y el nombre del modelo que elegiste como el mejor\n",
    "\n",
    "`helper.filter_log_book(log_book, <nombre de nuestro mejor modelo>)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### INICIO: TU CODIGO AQUI:  (~1 linea)###\n",
    "modelo = \n",
    "\n",
    "print(modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a utilizar el siguiente codigo para guardar el modelo elegido en un archivo.\n",
    "\n",
    "Esto genera 2 archivos, en un archivo _model.csv se tienen los parametros de el modelo elegido.\n",
    "\n",
    "El segundo archivo llamado _momentos.csv guarda la media y desviacion estandar de cada features, esto sera utilizado\n",
    "en la aplicacion hecha por el profesor para aplicar normalizacion al realizar predicciones.\n",
    "\n",
    "No hay que cambiar nada de codigo, solo hay que ejecutar la celda para exportar nuestro modelo y luego enviar los archivos .csv al profesor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def exportar_modelo(model,carnet):\n",
    "    norm_std, norm_media = helper.get_normalizacion_vales(X_train[:,0:5])\n",
    "    with open(carnet + '_model.csv', 'w') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        filewriter.writerow(model)\n",
    "        \n",
    "    with open(carnet + '_momentos.csv', 'w') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        filewriter.writerow(norm_std)\n",
    "        filewriter.writerow(norm_media)\n",
    "        \n",
    "    print('El modelo ha sido exportado [',csvfile.name,']')\n",
    "    \n",
    "exportar_modelo(modelo,carnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/ai_cancer.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Una vez elegido y exportado tu modelo , debes enviar los archivos .csv resultantes al profesor por correo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
